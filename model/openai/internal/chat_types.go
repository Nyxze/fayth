package internal

import (
	"encoding/json"
)

// Generated from https://platform.openai.com/docs/api-reference/chat/object

// ######## RESPONSE #############
// ChatCompletionResponse represents the response from a Chat Completions API call.
type ChatCompletionResponse struct {
	// Unique identifier for the chat completion.
	ID string `json:"id"`
	// Type of object returned, always "chat.completion".
	Object string `json:"object"`
	// Unix timestamp of when the completion was created in seconds
	Created int64 `json:"created"`
	// The model used to generate the completion.
	Model string `json:"model"`
	// List of completion choices (responses).
	Choices []ChatCompletionChoice `json:"choices"`
	// Token usage statistics.
	Usage CompletionUsage `json:"usage"`
	// Any of "auto", "default", "flex".
	ServiceTier string `json:"service_tier,omitempty"`
	// Internal system fingerprint identifying model and configuration.
	SystemFingerprint string `json:"system_fingerprint"`
}

// ChatCompletionChoice represents a single response choice in a chat completion.
type ChatCompletionChoice struct {
	Index        int                   `json:"index"`              // Index of the choice in the returned list.
	Message      ChatCompletionMessage `json:"message"`            // The message content generated by the model.
	Logprobs     *ChatLogprobs         `json:"logprobs,omitempty"` // Optional token-level log probability data.
	FinishReason string                `json:"finish_reason"`      // Reason why the model stopped generating (e.g., "stop", "length", "tool_calls").
}
type ChatCompletionMessage struct {
	// The contents of the message.
	Content string `json:"content"`
	// The refusal message generated by the model.
	Refusal string `json:"refusal"`
	// The role of the author of this message.
	Role string `json:"role"`
	// Annotations for the message, when applicable, as when using the
	// [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).
	Annotations []ChatAnnotation `json:"annotations"`
	// If the audio output modality is requested, this object contains data about the
	// audio response from the model.
	// [Learn more](https://platform.openai.com/docs/guides/audio).
	// Audio ChatCompletionAudio `json:"audio,nullable"`
	// The tool calls generated by the model, such as function calls.
	// ToolCalls []ChatCompletionMessageToolCall `json:"tool_calls"`
}

// ChatAnnotation provides additional metadata about parts of a message, such as citations.
type ChatAnnotation struct {
	Type        string           `json:"type"`                   // Type of annotation (e.g., "url_citation").
	URLCitation *ChatURLCitation `json:"url_citation,omitempty"` // Optional citation for URL-type annotations.
}

// ChatURLCitation describes a source citation pointing to a specific span in the message.
type ChatURLCitation struct {
	StartIndex int    `json:"start_index"` // Start character index of the span in the message.
	EndIndex   int    `json:"end_index"`   // End character index (exclusive) of the span.
	Title      string `json:"title"`       // Title of the cited source.
	URL        string `json:"url"`         // Full URL of the cited source.
}

// ChatLogprobs holds token-level log probability data, if requestedMessage
type ChatLogprobs struct {
	Content []ChatTokenLogprob `json:"content,omitempty"` // Token logprobs for content generation (if available).
	Refusal []ChatTokenLogprob `json:"refusal,omitempty"` // Token logprobs for refusal explanation (if available).
}

// ChatTokenLogprob represents log probability information for a single token.
type ChatTokenLogprob struct {
	Token       string           `json:"token"`                  // The generated token.
	Logprob     float64          `json:"logprob"`                // Log probability of the token.
	Bytes       []int            `json:"bytes,omitempty"`        // Optional byte values (for UTF-8 decoding).
	TopLogprobs []ChatTopLogprob `json:"top_logprobs,omitempty"` // Optional top alternative tokens with probabilities.
}

// ChatTopLogprob holds a candidate token and its log probability.
type ChatTopLogprob struct {
	Token   string  `json:"token"`           // Alternative token.
	Logprob float64 `json:"logprob"`         // Log probability of the alternative token.
	Bytes   []int   `json:"bytes,omitempty"` // Optional byte values of the token.
}

// CompletionUsage tracks token usage statistics for billing and monitoring.
type CompletionUsage struct {
	PromptTokens            int                         `json:"prompt_tokens"`             // Number of tokens in the input prompt.
	CompletionTokens        int                         `json:"completion_tokens"`         // Number of tokens in the model's reply.
	TotalTokens             int                         `json:"total_tokens"`              // Total number of tokens used.
	PromptTokensDetails     ChatPromptTokensDetails     `json:"prompt_tokens_details"`     // Breakdown of prompt tokens (audio, cached).
	CompletionTokensDetails ChatCompletionTokensDetails `json:"completion_tokens_details"` // Breakdown of completion tokens.
}

// ChatPromptTokensDetails gives a breakdown of prompt-related tokens.
type ChatPromptTokensDetails struct {
	AudioTokens  int `json:"audio_tokens"`  // Number of prompt tokens from audio inputs.
	CachedTokens int `json:"cached_tokens"` // Number of tokens reused from cache.
}

// ChatCompletionTokensDetails gives a breakdown of completion-related tokens.
type ChatCompletionTokensDetails struct {
	ReasoningTokens          int `json:"reasoning_tokens"`           // Tokens used in reasoning.
	AudioTokens              int `json:"audio_tokens"`               // Tokens generated from audio inputs.
	AcceptedPredictionTokens int `json:"accepted_prediction_tokens"` // Predicted tokens accepted by the system.
	RejectedPredictionTokens int `json:"rejected_prediction_tokens"` // Predicted tokens rejected (e.g., filtered).
}

//          ### Request ####

type ChatCompletionRequest struct {
	Messages    []ChatMessage `json:"messages"`
	Model       string        `json:"model"`
	Temperature float64       `json:"temperature"`
}

//	### MESSAGES ####

// ChatMessage represents struct used for exchanging with ChatModel
type ChatMessage struct {
	Role     Role   `json:"role"`
	Name     string `json:"name"`
	Contents []ChatContent
}

// Represent any kind of content that ChatCompletion can produce
// Field to read depend of the Type fied (e.g: Text field for type of "Text")
type ChatContent struct {
	Type ContentType
	Text string
}

func (c *ChatMessage) UnmarshalJSON(data []byte) error {
	// avoiding recursion
	type shadow ChatMessage
	type simple struct {
		shadow
		StringData string `json:"content"`
	}
	r := simple{}
	if err := json.Unmarshal(data, &r); err == nil {
		*c = ChatMessage(r.shadow)
		c.Contents = append(c.Contents, ChatContent{
			Type: TEXT,
			Text: r.StringData})
		return nil
	}
	type multi struct {
		shadow
		MultiContents []ChatContent `json:"content"`
	}
	mul := multi{}
	err := json.Unmarshal(data, &mul)
	if err == nil {
		*c = ChatMessage(mul.shadow)
		c.Contents = mul.MultiContents
	}
	return err
}

func (c ChatMessage) MarshalJSON() ([]byte, error) {

	return nil, nil
}
