package internal

// Generated from https://platform.openai.com/docs/api-reference/chat/object

// ChatCompletionResponse represents the response from a Chat Completions API call.
type ChatCompletionResponse struct {
	ID                string       `json:"id"`                     // Unique identifier for the chat completion.
	Object            string       `json:"object"`                 // Type of object returned, always "chat.completion".
	Created           int64        `json:"created"`                // Unix timestamp of when the completion was created.
	Model             string       `json:"model"`                  // The model used to generate the completion.
	Choices           []ChatChoice `json:"choices"`                // List of completion choices (responses).
	Usage             ChatUsage    `json:"usage"`                  // Token usage statistics.
	ServiceTier       string       `json:"service_tier,omitempty"` // Optional service tier (e.g. "standard", "professional").
	SystemFingerprint string       `json:"system_fingerprint"`     // Internal system fingerprint identifying model and configuration.
}

// ChatChoice represents a single response choice in a chat completion.
type ChatChoice struct {
	Index        int           `json:"index"`              // Index of the choice in the returned list.
	Message      ChatMessage   `json:"message"`            // The message content generated by the model.
	Logprobs     *ChatLogprobs `json:"logprobs,omitempty"` // Optional token-level log probability data.
	FinishReason string        `json:"finish_reason"`      // Reason why the model stopped generating (e.g., "stop", "length", "tool_calls").
}

// ChatMessage represents a message from the model, including optional annotations and refusal messages.
type ChatMessage struct {
	Role        string           `json:"role"`                  // Role of the message sender (e.g., "assistant", "user").
	Content     string           `json:"content,omitempty"`     // The text content of the message.
	Refusal     string           `json:"refusal,omitempty"`     // Optional refusal explanation (why content wasn't generated).
	Annotations []ChatAnnotation `json:"annotations,omitempty"` // Optional structured annotations for sources or citations.
}

// ChatAnnotation provides additional metadata about parts of a message, such as citations.
type ChatAnnotation struct {
	Type        string           `json:"type"`                   // Type of annotation (e.g., "url_citation").
	URLCitation *ChatURLCitation `json:"url_citation,omitempty"` // Optional citation for URL-type annotations.
}

// ChatURLCitation describes a source citation pointing to a specific span in the message.
type ChatURLCitation struct {
	StartIndex int    `json:"start_index"` // Start character index of the span in the message.
	EndIndex   int    `json:"end_index"`   // End character index (exclusive) of the span.
	Title      string `json:"title"`       // Title of the cited source.
	URL        string `json:"url"`         // Full URL of the cited source.
}

// ChatLogprobs holds token-level log probability data, if requested.
type ChatLogprobs struct {
	Content []ChatTokenLogprob `json:"content,omitempty"` // Token logprobs for content generation (if available).
	Refusal []ChatTokenLogprob `json:"refusal,omitempty"` // Token logprobs for refusal explanation (if available).
}

// ChatTokenLogprob represents log probability information for a single token.
type ChatTokenLogprob struct {
	Token       string           `json:"token"`                  // The generated token.
	Logprob     float64          `json:"logprob"`                // Log probability of the token.
	Bytes       []int            `json:"bytes,omitempty"`        // Optional byte values (for UTF-8 decoding).
	TopLogprobs []ChatTopLogprob `json:"top_logprobs,omitempty"` // Optional top alternative tokens with probabilities.
}

// ChatTopLogprob holds a candidate token and its log probability.
type ChatTopLogprob struct {
	Token   string  `json:"token"`           // Alternative token.
	Logprob float64 `json:"logprob"`         // Log probability of the alternative token.
	Bytes   []int   `json:"bytes,omitempty"` // Optional byte values of the token.
}

// ChatUsage tracks token usage statistics for billing and monitoring.
type ChatUsage struct {
	PromptTokens            int                         `json:"prompt_tokens"`             // Number of tokens in the input prompt.
	CompletionTokens        int                         `json:"completion_tokens"`         // Number of tokens in the model's reply.
	TotalTokens             int                         `json:"total_tokens"`              // Total number of tokens used.
	PromptTokensDetails     ChatPromptTokensDetails     `json:"prompt_tokens_details"`     // Breakdown of prompt tokens (audio, cached).
	CompletionTokensDetails ChatCompletionTokensDetails `json:"completion_tokens_details"` // Breakdown of completion tokens.
}

// ChatPromptTokensDetails gives a breakdown of prompt-related tokens.
type ChatPromptTokensDetails struct {
	AudioTokens  int `json:"audio_tokens"`  // Number of prompt tokens from audio inputs.
	CachedTokens int `json:"cached_tokens"` // Number of tokens reused from cache.
}

// ChatCompletionTokensDetails gives a breakdown of completion-related tokens.
type ChatCompletionTokensDetails struct {
	ReasoningTokens          int `json:"reasoning_tokens"`           // Tokens used in reasoning.
	AudioTokens              int `json:"audio_tokens"`               // Tokens generated from audio inputs.
	AcceptedPredictionTokens int `json:"accepted_prediction_tokens"` // Predicted tokens accepted by the system.
	RejectedPredictionTokens int `json:"rejected_prediction_tokens"` // Predicted tokens rejected (e.g., filtered).
}
