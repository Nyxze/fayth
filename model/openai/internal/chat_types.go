package internal

import (
	"bytes"
	"encoding/json"
	"fmt"
	"nyxze/fayth/model"
)

// Generated from https://platform.openai.com/docs/api-reference/chat/object

// ######## RESPONSE #############
// ChatCompletionResponse represents the response from a Chat Completions API call.
type ChatCompletionResponse struct {
	// Unique identifier for the chat completion.
	ID string `json:"id"`
	// Type of object returned, always "chat.completion".
	Object string `json:"object"`
	// Unix timestamp of when the completion was created in seconds
	Created int64 `json:"created"`
	// The model used to generate the completion.
	Model string `json:"model"`
	// List of completion choices (responses).
	Choices []ChatCompletionChoice `json:"choices"`
	// Token usage statistics.
	Usage CompletionUsage `json:"usage"`
	// Any of "auto", "default", "flex".
	ServiceTier string `json:"service_tier,omitempty"`
	// Internal system fingerprint identifying model and configuration.
	SystemFingerprint string `json:"system_fingerprint"`
}

// ChatCompletionChoice represents a single response choice in a chat completion.
type ChatCompletionChoice struct {
	Index        int                   `json:"index"`              // Index of the choice in the returned list.
	Message      ChatCompletionMessage `json:"message"`            // The message content generated by the model.
	Logprobs     *ChatLogprobs         `json:"logprobs,omitempty"` // Optional token-level log probability data.
	FinishReason string                `json:"finish_reason"`      // Reason why the model stopped generating (e.g., "stop", "length", "tool_calls").
}
type ChatCompletionMessage struct {
	// The contents of the message.
	Content string `json:"content"`
	// The refusal message generated by the model.
	Refusal string `json:"refusal"`
	// The role of the author of this message.
	Role string `json:"role"`
	// Annotations for the message, when applicable, as when using the
	// [web search tool](https://platform.openai.com/docs/guides/tools-web-search?api-mode=chat).
	Annotations []ChatAnnotation `json:"annotations"`
	// If the audio output modality is requested, this object contains data about the
	// audio response from the model.
	// [Learn more](https://platform.openai.com/docs/guides/audio).
	// Audio ChatCompletionAudio `json:"audio,nullable"`
	// The tool calls generated by the model, such as function calls.
	// ToolCalls []ChatCompletionMessageToolCall `json:"tool_calls"`
}

// ChatAnnotation provides additional metadata about parts of a message, such as citations.
type ChatAnnotation struct {
	Type        string           `json:"type"`                   // Type of annotation (e.g., "url_citation").
	URLCitation *ChatURLCitation `json:"url_citation,omitempty"` // Optional citation for URL-type annotations.
}

// ChatURLCitation describes a source citation pointing to a specific span in the message.
type ChatURLCitation struct {
	StartIndex int    `json:"start_index"` // Start character index of the span in the message.
	EndIndex   int    `json:"end_index"`   // End character index (exclusive) of the span.
	Title      string `json:"title"`       // Title of the cited source.
	URL        string `json:"url"`         // Full URL of the cited source.
}

// ChatLogprobs holds token-level log probability data, if requestedMessage
type ChatLogprobs struct {
	Content []ChatTokenLogprob `json:"content,omitempty"` // Token logprobs for content generation (if available).
	Refusal []ChatTokenLogprob `json:"refusal,omitempty"` // Token logprobs for refusal explanation (if available).
}

// ChatTokenLogprob represents log probability information for a single token.
type ChatTokenLogprob struct {
	Token       string           `json:"token"`                  // The generated token.
	Logprob     float64          `json:"logprob"`                // Log probability of the token.
	Bytes       []int            `json:"bytes,omitempty"`        // Optional byte values (for UTF-8 decoding).
	TopLogprobs []ChatTopLogprob `json:"top_logprobs,omitempty"` // Optional top alternative tokens with probabilities.
}

// ChatTopLogprob holds a candidate token and its log probability.
type ChatTopLogprob struct {
	Token   string  `json:"token"`           // Alternative token.
	Logprob float64 `json:"logprob"`         // Log probability of the alternative token.
	Bytes   []int   `json:"bytes,omitempty"` // Optional byte values of the token.
}

// CompletionUsage tracks token usage statistics for billing and monitoring.
type CompletionUsage struct {
	PromptTokens            int                         `json:"prompt_tokens"`             // Number of tokens in the input prompt.
	CompletionTokens        int                         `json:"completion_tokens"`         // Number of tokens in the model's reply.
	TotalTokens             int                         `json:"total_tokens"`              // Total number of tokens used.
	PromptTokensDetails     ChatPromptTokensDetails     `json:"prompt_tokens_details"`     // Breakdown of prompt tokens (audio, cached).
	CompletionTokensDetails ChatCompletionTokensDetails `json:"completion_tokens_details"` // Breakdown of completion tokens.
}

// ChatPromptTokensDetails gives a breakdown of prompt-related tokens.
type ChatPromptTokensDetails struct {
	AudioTokens  int `json:"audio_tokens"`  // Number of prompt tokens from audio inputs.
	CachedTokens int `json:"cached_tokens"` // Number of tokens reused from cache.
}

// ChatCompletionTokensDetails gives a breakdown of completion-related tokens.
type ChatCompletionTokensDetails struct {
	ReasoningTokens          int `json:"reasoning_tokens"`           // Tokens used in reasoning.
	AudioTokens              int `json:"audio_tokens"`               // Tokens generated from audio inputs.
	AcceptedPredictionTokens int `json:"accepted_prediction_tokens"` // Predicted tokens accepted by the system.
	RejectedPredictionTokens int `json:"rejected_prediction_tokens"` // Predicted tokens rejected (e.g., filtered).
}

//          ### Request ####

// ChatCompletionRequest represents a request to the OpenAI Chat Completions API
type ChatCompletionRequest struct {
	// Required fields
	Messages []ChatMessage `json:"messages"` // List of messages in the conversation
	Model    string        `json:"model"`    // Model to use for completion

	// Sampling parameters
	Temperature float64 `json:"temperature,omitzero"` // Controls randomness (0.0 to 2.0)
	TopP        float64 `json:"top_p,omitzero"`       // Nucleus sampling parameter (0.0 to 1.0)
	MaxTokens   int     `json:"max_tokens,omitzero"`  // Maximum tokens to generate

	// Penalty parameters
	FrequencyPenalty float64 `json:"frequency_penalty,omitzero"` // Frequency penalty (-2.0 to 2.0)
	PresencePenalty  float64 `json:"presence_penalty,omitzero"`  // Presence penalty (-2.0 to 2.0)

	// Control parameters
	Stop []string `json:"stop,omitzero"` // Stop sequences
	Seed int64    `json:"seed,omitzero"` // Seed for deterministic sampling
	User string   `json:"user,omitzero"` // User identifier for abuse monitoring

	// Response format
	ResponseFormat ResponseFormat `json:"response_format,omitzero"` // Response format specification

	// Streaming and logging
	Stream      bool `json:"stream,omitzero"`       // Enable streaming responses
	LogProbs    bool `json:"logprobs,omitzero"`     // Include log probabilities
	TopLogProbs int  `json:"top_logprobs,omitzero"` // Number of top log probabilities (0-20)
}

// ResponseFormat specifies the format of the model's output
type ResponseFormat struct {
	Type string `json:"type"` // "text" or "json_object"
}

//	### MESSAGES ####

// ChatMessage represents struct used for exchanging with ChatModel
type ChatMessage struct {
	// The role of the messages author
	Role Role `json:"role"`
	// An optional name for the participant
	Name string `json:"name"`

	// Contents of the message
	Contents []ChatContent `json:"-"`
}

func (c *ChatMessage) UnmarshalJSON(data []byte) error {
	// avoiding recursion
	type shadow ChatMessage
	type simple struct {
		shadow
		StringData string `json:"content"`
	}
	r := simple{}
	if err := json.Unmarshal(data, &r); err == nil {
		*c = ChatMessage(r.shadow)
		c.Contents = append(c.Contents, ChatContent{
			Type: TextContent,
			Text: r.StringData})
		return nil
	}
	type multi struct {
		shadow
		MultiContents []ChatContent `json:"content"`
	}
	mul := multi{}
	err := json.Unmarshal(data, &mul)
	if err == nil {
		*c = ChatMessage(mul.shadow)
		c.Contents = mul.MultiContents
	}
	return err
}

func (c ChatMessage) MarshalJSON() ([]byte, error) {
	// avoiding recursion
	type alias ChatMessage
	var buffer bytes.Buffer
	encoder := json.NewEncoder(&buffer)

	// Simple case
	if c.isSimpleMessage() {
		ret := struct {
			alias
			Content string `json:"content"`
		}{
			alias: alias(c),
		}
		err := encoder.Encode(ret)
		return buffer.Bytes(), err
	}

	// Multi content
	return json.Marshal(struct {
		Role    string        `json:"role"`
		Name    string        `json:"name,omitempty"`
		Content []ChatContent `json:"content"`
	}{
		Role:    c.Role,
		Name:    c.Name,
		Content: c.Contents,
	})
}

// Represent any kind of content that ChatCompletion can produce
// Field to read depend of the Type fied (e.g: Text field for type of "Text")
type ChatContent struct {
	Type  ContentType `json:"type"`
	Text  string      `json:"text,omitempty"`
	Audio struct {
		Data   string `json:"data"`
		Format string `json:"format"`
	} `json:"input_audio,omitzero"`
	Image struct {
		Url    string `json:"url"`
		Detail string `json:"detail"`
	} `json:"image_url,omitzero"`
}

func (c ChatContent) MarshalJSON() ([]byte, error) {
	type base struct {
		Type ContentType `json:"type"`
	}

	switch c.Type {
	case TextContent:
		return json.Marshal(struct {
			base
			Text string `json:"text"`
		}{
			base: base{Type: c.Type},
			Text: c.Text,
		})
	default:
		return nil, fmt.Errorf("unsupported content type: %s", c.Type)
	}
}

func (c ChatMessage) isSimpleMessage() bool {
	return len(c.Contents) == 1 && c.Contents[0].Text == TextContent
}

// Adapter between model API <=> internal API
func ToContentPart(contents []ChatContent) []model.ContentPart {
	parts := make([]model.ContentPart, 0, len(contents))
	for _, c := range contents {
		switch c.Type {
		case TextContent:
			parts = append(parts, model.TextContent{Text: c.Text})
		}
	}
	return parts
}
func ToChatContent(contents []model.ContentPart) []ChatContent {
	parts := make([]ChatContent, 0, len(contents))
	for _, c := range contents {
		switch c.Kind() {
		case model.TextKind:
			parts = append(parts, ChatContent{
				Type: TextContent,
				Text: c.(model.TextContent).Text,
			})
		}
	}
	return parts
}

// ChatCompletionStreamResponse represents a streaming response chunk from the OpenAI API
type ChatCompletionStreamResponse struct {
	ID      string                `json:"id"`
	Object  string                `json:"object"`
	Created int64                 `json:"created"`
	Model   string                `json:"model"`
	Choices []ChatStreamingChoice `json:"choices"`
}

// ChatStreamingChoice represents a single choice in a streaming response
type ChatStreamingChoice struct {
	Index        int                   `json:"index"`
	Delta        ChatCompletionMessage `json:"delta"`
	FinishReason string                `json:"finish_reason"`
}
